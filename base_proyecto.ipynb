{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "oZdfijZyFVnP",
      "metadata": {
        "id": "oZdfijZyFVnP"
      },
      "source": [
        "# Trabajando con Pandas, MySQL y Google BigQuery\n",
        "\n",
        "En este ejercicio, vamos a aprender cómo interactuar con una base de datos MySQL utilizando Pandas y luego cargar los datos en Google BigQuery. Siga las instrucciones a continuación para completar el ejercicio."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oswdyc6PFbVk",
      "metadata": {
        "id": "oswdyc6PFbVk"
      },
      "source": [
        "## Paso 1: Instalación de paquetes\n",
        "\n",
        "Instale los siguientes paquetes utilizando `pip`:\n",
        "\n",
        "1. mysql-connector-python\n",
        "2. google-cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dBaVCoFWFfdC",
      "metadata": {
        "id": "dBaVCoFWFfdC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-8.0.33-cp311-cp311-win_amd64.whl (9.6 MB)\n",
            "     ---------------------------------------- 9.6/9.6 MB 29.2 MB/s eta 0:00:00\n",
            "Collecting protobuf<=3.20.3,>=3.11.0\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "     -------------------------------------- 162.1/162.1 kB 9.5 MB/s eta 0:00:00\n",
            "Installing collected packages: protobuf, mysql-connector-python\n",
            "Successfully installed mysql-connector-python-8.0.33 protobuf-3.20.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.2\n",
            "[notice] To update, run: c:\\Users\\GGudino\\OneDrive - COA S.A\\Documentos\\GitHub\\trabajo_py_dev\\venvp\\Scripts\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-cloud-bigquery\n",
            "  Downloading google_cloud_bigquery-3.11.3-py2.py3-none-any.whl (219 kB)\n",
            "     -------------------------------------- 219.5/219.5 kB 4.5 MB/s eta 0:00:00\n",
            "Collecting grpcio<2.0dev,>=1.47.0\n",
            "  Downloading grpcio-1.56.0-cp311-cp311-win_amd64.whl (4.2 MB)\n",
            "     ---------------------------------------- 4.2/4.2 MB 26.9 MB/s eta 0:00:00\n",
            "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
            "  Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
            "     -------------------------------------- 120.5/120.5 kB 7.4 MB/s eta 0:00:00\n",
            "Collecting proto-plus<2.0.0dev,>=1.15.0\n",
            "  Downloading proto_plus-1.22.3-py3-none-any.whl (48 kB)\n",
            "     ---------------------------------------- 48.1/48.1 kB 2.4 MB/s eta 0:00:00\n",
            "Collecting google-cloud-core<3.0.0dev,>=1.6.0\n",
            "  Downloading google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB)\n",
            "Collecting google-resumable-media<3.0dev,>=0.6.0\n",
            "  Downloading google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB)\n",
            "     ---------------------------------------- 77.7/77.7 kB 4.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: packaging>=20.0.0 in c:\\users\\ggudino\\onedrive - coa s.a\\documentos\\github\\trabajo_py_dev\\venvp\\lib\\site-packages (from google-cloud-bigquery) (23.1)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\ggudino\\onedrive - coa s.a\\documentos\\github\\trabajo_py_dev\\venvp\\lib\\site-packages (from google-cloud-bigquery) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in c:\\users\\ggudino\\onedrive - coa s.a\\documentos\\github\\trabajo_py_dev\\venvp\\lib\\site-packages (from google-cloud-bigquery) (2.8.2)\n",
            "Collecting requests<3.0.0dev,>=2.21.0\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "     ---------------------------------------- 62.6/62.6 kB ? eta 0:00:00\n",
            "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.59.1-py2.py3-none-any.whl (224 kB)\n",
            "     ------------------------------------- 224.5/224.5 kB 14.3 MB/s eta 0:00:00\n",
            "Collecting google-auth<3.0.dev0,>=2.14.1\n",
            "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
            "     -------------------------------------- 181.8/181.8 kB 5.5 MB/s eta 0:00:00\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
            "  Downloading grpcio_status-1.56.0-py3-none-any.whl (5.1 kB)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.5.0-cp311-cp311-win_amd64.whl (27 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ggudino\\onedrive - coa s.a\\documentos\\github\\trabajo_py_dev\\venvp\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.2.0-cp311-cp311-win_amd64.whl (96 kB)\n",
            "     ---------------------------------------- 96.6/96.6 kB 5.8 MB/s eta 0:00:00\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
            "     -------------------------------------- 123.6/123.6 kB 7.1 MB/s eta 0:00:00\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "     -------------------------------------- 143.1/143.1 kB 8.3 MB/s eta 0:00:00\n",
            "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5\n",
            "  Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl (422 kB)\n",
            "     ------------------------------------- 422.5/422.5 kB 27.5 MB/s eta 0:00:00\n",
            "Collecting pyasn1<0.6.0,>=0.4.6\n",
            "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "Installing collected packages: urllib3, pyasn1, protobuf, idna, grpcio, google-crc32c, charset-normalizer, certifi, cachetools, rsa, requests, pyasn1-modules, proto-plus, googleapis-common-protos, google-resumable-media, grpcio-status, google-auth, google-api-core, google-cloud-core, google-cloud-bigquery\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "Successfully installed cachetools-5.3.1 certifi-2023.5.7 charset-normalizer-3.2.0 google-api-core-2.11.1 google-auth-2.22.0 google-cloud-bigquery-3.11.3 google-cloud-core-2.3.3 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.59.1 grpcio-1.56.0 grpcio-status-1.56.0 idna-3.4 proto-plus-1.22.3 protobuf-4.23.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.31.0 rsa-4.9 urllib3-1.26.16\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mysql-connector-python 8.0.33 requires protobuf<=3.20.3,>=3.11.0, but you have protobuf 4.23.4 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.2\n",
            "[notice] To update, run: c:\\Users\\GGudino\\OneDrive - COA S.A\\Documentos\\GitHub\\trabajo_py_dev\\venvp\\Scripts\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "  Using cached pandas-2.0.3-cp311-cp311-win_amd64.whl (10.6 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ggudino\\onedrive - coa s.a\\documentos\\github\\trabajo_py_dev\\venvp\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Collecting pytz>=2020.1\n",
            "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "Collecting tzdata>=2022.1\n",
            "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "Collecting numpy>=1.21.0\n",
            "  Using cached numpy-1.25.1-cp311-cp311-win_amd64.whl (15.0 MB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ggudino\\onedrive - coa s.a\\documentos\\github\\trabajo_py_dev\\venvp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Installing collected packages: pytz, tzdata, numpy, pandas\n",
            "Successfully installed numpy-1.25.1 pandas-2.0.3 pytz-2023.3 tzdata-2023.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.2\n",
            "[notice] To update, run: c:\\Users\\GGudino\\OneDrive - COA S.A\\Documentos\\GitHub\\trabajo_py_dev\\venvp\\Scripts\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyarrow\n",
            "  Downloading pyarrow-12.0.1-cp311-cp311-win_amd64.whl (21.5 MB)\n",
            "     --------------------------------------- 21.5/21.5 MB 15.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\ggudino\\onedrive - coa s.a\\documentos\\github\\trabajo_py_dev\\venvp\\lib\\site-packages (from pyarrow) (1.25.1)\n",
            "Installing collected packages: pyarrow\n",
            "Successfully installed pyarrow-12.0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.2\n",
            "[notice] To update, run: c:\\Users\\GGudino\\OneDrive - COA S.A\\Documentos\\GitHub\\trabajo_py_dev\\venvp\\Scripts\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# %pip install mysql-connector-python\n",
        "# %pip install google-cloud-bigquery\n",
        "# %pip install pandas\n",
        "# %pip install pyarrow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pXLyoVLqFgpL",
      "metadata": {
        "id": "pXLyoVLqFgpL"
      },
      "source": [
        "## Paso 2: Importar paquetes necesarios\n",
        "\n",
        "Importe los siguientes paquetes:\n",
        "\n",
        "1. mysql\n",
        "2. pandas\n",
        "3. mysql.connector\n",
        "4. google.cloud.bigquery\n",
        "5. os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "VF6Il9oZFj1c",
      "metadata": {
        "id": "VF6Il9oZFj1c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import mysql.connector as connection\n",
        "from google.cloud import bigquery\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7zA258NLFkci",
      "metadata": {
        "id": "7zA258NLFkci"
      },
      "source": [
        "## Paso 3: Establecer la conexión con la base de datos MySQL\n",
        "\n",
        "Complete el siguiente código para establecer una conexión con la base de datos MySQL:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sWFXcH6jFrUL",
      "metadata": {
        "id": "sWFXcH6jFrUL"
      },
      "source": [
        "```\n",
        "mydb = mysql.connector.connect(\n",
        "    host=\"\",\n",
        "    user=\"\",\n",
        "    passwd=\"\",\n",
        "    database=\"\"\n",
        ")\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ah9E3APyFqXm",
      "metadata": {
        "id": "ah9E3APyFqXm"
      },
      "outputs": [],
      "source": [
        "mydb = connection.connect(\n",
        "    host=\"34.29.102.210\", \n",
        "    user=\"usuario-py\",\n",
        "    passwd=\"123456789\",\n",
        "    database=\"retail_db\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YaFj_e7lF0Kg",
      "metadata": {
        "id": "YaFj_e7lF0Kg"
      },
      "source": [
        "## Paso 4: Leer los datos de la base de datos MySQL utilizando Pandas\n",
        "\n",
        "Escriba el código para leer los datos de la tabla `categories` de la base de datos MySQL utilizando Pandas y almacenarlos en un DataFrame llamado `df`. No olvide cerrar la conexión a la base de datos después de realizar la consulta.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "CLdryJrWF2PG",
      "metadata": {
        "id": "CLdryJrWF2PG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\GGudino\\AppData\\Local\\Temp\\ipykernel_9888\\2935381959.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df = pd.read_sql(sql, mydb)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category_id</th>\n",
              "      <th>category_department_id</th>\n",
              "      <th>category_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Football</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Soccer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Baseball &amp; Softball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>Basketball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>Lacrosse</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category_id  category_department_id        category_name\n",
              "0            1                       2             Football\n",
              "1            2                       2               Soccer\n",
              "2            3                       2  Baseball & Softball\n",
              "3            4                       2           Basketball\n",
              "4            5                       2             Lacrosse"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sql = \"SELECT * FROM retail_db.categories\"\n",
        "df = pd.read_sql(sql, mydb)\n",
        "mydb.close()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZbTJHPnuF4yI",
      "metadata": {
        "id": "ZbTJHPnuF4yI"
      },
      "source": [
        "## Paso 5: Configurar las credenciales de Google Cloud\n",
        "\n",
        "Agregue el archivo JSON de las credenciales de su cuenta de Google Cloud al entorno de ejecución y establezca la variable de entorno `GOOGLE_APPLICATION_CREDENTIALS` con la ruta al archivo JSON.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "F_0rWVA6F5cj",
      "metadata": {
        "id": "F_0rWVA6F5cj"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"service.json\" "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6HRVRXjmF6rR",
      "metadata": {
        "id": "6HRVRXjmF6rR"
      },
      "source": [
        "## Paso 6: Crear un cliente de BigQuery\n",
        "\n",
        "Escriba el código para crear un objeto cliente de BigQuery.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "WuSKbz2xF9HO",
      "metadata": {
        "id": "WuSKbz2xF9HO"
      },
      "outputs": [],
      "source": [
        "# client = bigquery.Client()\n",
        "# Si usamos el archivo de servicio:\n",
        "client = bigquery.Client.from_service_account_json(\"service.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "R1PwRWTEF9ZD",
      "metadata": {
        "id": "R1PwRWTEF9ZD"
      },
      "source": [
        "## Paso 7: Escribir los datos del DataFrame en Google BigQuery\n",
        "\n",
        "Escriba el código necesario para escribir los datos del DataFrame `df` en la tabla `ar_dp_dtkl_raw.categories` en Google BigQuery. Utilice la opción \"WRITE_TRUNCATE\" para sobrescribir cualquier dato existente en la tabla.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "Gjfa5JD2F_PE",
      "metadata": {
        "id": "Gjfa5JD2F_PE"
      },
      "outputs": [],
      "source": [
        "tabla_id = \"acquired-script-391200.ar_dp_dtkl_raw.categories\"\n",
        "tabla_property = client.get_table(tabla_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f24c1c81",
      "metadata": {},
      "outputs": [],
      "source": [
        "job_configuration = bigquery.LoadJobConfig(\n",
        "    schema = tabla_property.schema,\n",
        "    write_disposition = \"WRITE_TRUNCATE\" # alternativas: WRITE_APPEND (agrega a la cola), WRITE_EMPTY (solo carga si esta vacía)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6a520758",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Carga completada\n"
          ]
        }
      ],
      "source": [
        "job = client.load_table_from_dataframe(\n",
        "    df, tabla_id, job_config=job_configuration\n",
        ")\n",
        "\n",
        "job.result() #esperar a que se complete la carga\n",
        "print(\"Carga completada\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m104",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m104"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
